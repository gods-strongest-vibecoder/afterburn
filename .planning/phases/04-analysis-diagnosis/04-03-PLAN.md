---
phase: 04-analysis-diagnosis
plan: 03
type: execute
wave: 2
depends_on: ["04-01", "04-02"]
files_modified:
  - src/analysis/ui-auditor.ts
  - src/analysis/index.ts
  - src/index.ts
autonomous: true

must_haves:
  truths:
    - "Vision LLM analyzes screenshots and detects layout issues (cramped elements, overlapping content)"
    - "Vision LLM detects poor contrast, readability problems, and formatting issues"
    - "AI provides UI improvement suggestions in plain English without jargon"
    - "Analysis phase is wired into main pipeline after execution, before reporting"
    - "--source flag accepted from CLI and passed to analysis phase"
    - "Analysis artifact saved to .afterburn/artifacts/ for Phase 5 reporting"
    - "Tool works end-to-end: discovery -> execution -> analysis with AI diagnosis"
  artifacts:
    - path: "src/analysis/ui-auditor.ts"
      provides: "Vision LLM screenshot analysis for UI/UX issues"
      exports: ["auditUI"]
    - path: "src/analysis/index.ts"
      provides: "Public API for all analysis modules"
      exports: ["analyzeErrors", "auditUI", "mapErrorToSource"]
    - path: "src/index.ts"
      provides: "Main pipeline with Phase 4 analysis stage integrated"
  key_links:
    - from: "src/analysis/ui-auditor.ts"
      to: "src/ai/gemini-client.ts"
      via: "GeminiClient.generateStructuredWithImage for vision analysis"
      pattern: "generateStructuredWithImage"
    - from: "src/analysis/ui-auditor.ts"
      to: "src/analysis/diagnosis-schema.ts"
      via: "UIAuditSchema for structured output"
      pattern: "UIAuditSchema"
    - from: "src/index.ts"
      to: "src/analysis/index.ts"
      via: "imports analyzeErrors, auditUI for pipeline integration"
      pattern: "import.*analysis"
    - from: "src/index.ts"
      to: "src/analysis/source-mapper.ts"
      via: "imports mapErrorToSource when --source flag provided"
      pattern: "mapErrorToSource|source-mapper"
---

<objective>
Create vision-powered UI auditor and wire the complete analysis phase into the main pipeline with --source CLI flag support.

Purpose: This plan completes Phase 4 by adding the visual AI analysis (screenshots -> UI issue detection) and connecting all analysis modules into the running pipeline. After this, Afterburn transforms raw test results into actionable, plain-English insights.

Output: ui-auditor.ts for vision analysis, updated index.ts barrel exports, and fully integrated main pipeline with Phase 4 analysis stage.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-analysis-diagnosis/04-RESEARCH.md

# Prior plan summaries (needed for exports and types)
@.planning/phases/04-analysis-diagnosis/04-01-SUMMARY.md
@.planning/phases/04-analysis-diagnosis/04-02-SUMMARY.md

# Key source files
@src/ai/gemini-client.ts
@src/analysis/diagnosis-schema.ts
@src/analysis/error-analyzer.ts
@src/analysis/source-mapper.ts
@src/analysis/index.ts
@src/index.ts
@src/types/execution.ts
@src/types/artifacts.ts
@src/execution/workflow-executor.ts
@src/artifacts/artifact-storage.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Vision-powered UI auditor</name>
  <files>src/analysis/ui-auditor.ts, src/analysis/index.ts</files>
  <action>
**Create src/analysis/ui-auditor.ts** with:

1. `auditUI(artifact: ExecutionArtifact, options?: { apiKey?: string }): Promise<UIAuditResult[]>` - main export:
   - If GEMINI_API_KEY not available: return empty array with console warning "UI auditing requires GEMINI_API_KEY. Skipping visual analysis."
   - Collect all screenshots to audit:
     - From pageAudits (pages that were accessibility/performance audited - these have screenshots from discovery)
     - From failed step evidence (error screenshots captured by Phase 3)
     - Deduplicate by screenshot path
   - For each unique screenshot with a valid pngPath:
     - Call vision LLM with the screenshot
     - Parse structured response into UIAuditResult

2. Vision LLM analysis (`auditScreenshot`):
   - Build prompt for Gemini vision:
     ```
     You are a UI/UX expert reviewing a web page screenshot. Analyze it for visual issues.

     Page URL: {pageUrl}

     Look for these specific issues:

     1. LAYOUT ISSUES: Elements overlapping, cramped spacing, content cut off at edges,
        misaligned sections, inconsistent margins/padding, elements pushed off-screen

     2. CONTRAST & READABILITY: Text hard to read against background, insufficient color
        contrast (WCAG AA requires 4.5:1 for normal text), tiny font sizes, light gray
        text on white background

     3. FORMATTING ISSUES: Text truncated with "...", buttons too small to tap on mobile,
        inconsistent font sizes, broken grid layouts, images stretched or squished

     4. IMPROVEMENT SUGGESTIONS: What would make this page better for users?
        Write suggestions in plain English as if explaining to someone who built this
        with AI tools and doesn't know CSS deeply.

     Be specific about WHERE on the page each issue appears (top, bottom, left sidebar, etc).
     Only report issues you are confident about. If the page looks fine, say so.
     ```
   - Call `gemini.generateStructuredWithImage(prompt, UIAuditSchema, screenshotPngPath)`
   - Wrap result as UIAuditResult with pageUrl and screenshotRef

3. Screenshot collection helper (`collectAuditableScreenshots`):
   - From ExecutionArtifact, gather screenshots from:
     - `workflowResults[].stepResults[].evidence?.screenshotRef` (error screenshots)
     - Note: pageAudits from Phase 3 don't have screenshots stored directly -- they are URL-based audits
   - Also check for discovery screenshots: look for discovery artifact screenshots by reading the discovery artifact JSON from `.afterburn/artifacts/discovery-{sessionId}.json` if it exists
   - BUT simpler approach: just audit the error screenshots from execution (they are the most relevant for UI issues anyway)
   - Actually, the cleanest approach: accept an optional `screenshotPaths` parameter with array of `{ url: string, pngPath: string }[]` that the pipeline can pass in
   - Deduplicate by pngPath, verify file exists before attempting vision analysis

4. Error handling:
   - If a single screenshot analysis fails (API error, file not found): log warning, skip that screenshot, continue with others
   - If all fail: return empty array
   - Wrap each analysis in try/catch

**Update src/analysis/index.ts** barrel exports to include ui-auditor.ts:
- Export everything from diagnosis-schema.ts
- Export everything from error-analyzer.ts
- Export everything from source-mapper.ts
- Export everything from ui-auditor.ts

Add 1-2 line header comment to ui-auditor.ts.
  </action>
  <verify>Run `npx tsc --noEmit` to confirm no type errors. Verify ui-auditor.ts exports auditUI function and index.ts re-exports all analysis modules.</verify>
  <done>Vision-powered UI auditor analyzes screenshots for layout, contrast, formatting issues using Gemini vision. Returns structured UIAuditResult array. Gracefully skips when no API key set. All analysis modules exported from index.ts barrel.</done>
</task>

<task type="auto">
  <name>Task 2: Wire analysis phase into main pipeline with --source flag</name>
  <files>src/index.ts</files>
  <action>
**Update src/index.ts** to add Phase 4 analysis after execution:

1. Parse `--source` CLI flag:
   - Add after existing --password parsing block:
     ```typescript
     let sourcePath: string | undefined;
     const sourceIndex = process.argv.indexOf('--source');
     if (sourceIndex !== -1 && process.argv[sourceIndex + 1]) {
       sourcePath = process.argv[sourceIndex + 1];
     }
     ```
   - Update usage string to include: `[--source ./path]`

2. Add imports at top:
   ```typescript
   import { analyzeErrors, auditUI, mapErrorToSource } from './analysis/index.js';
   import type { AnalysisArtifact, DiagnosedError, UIAuditResult } from './analysis/index.js';
   import { ArtifactStorage } from './artifacts/index.js';
   ```

3. After execution results are printed (after `console.log(\`Total issues found: ...\`)`) and BEFORE `process.exit()`, add Phase 4 analysis:
   ```
   // Phase 4: Analyze execution results
   console.log('\nStarting analysis...\n');

   // Error diagnosis
   const diagnosedErrors = await analyzeErrors(executionResult);

   // Source code mapping (if --source provided)
   if (sourcePath) {
     console.log(`  Cross-referencing with source code: ${sourcePath}`);
     for (const diagnosed of diagnosedErrors) {
       if (diagnosed.error) {
         const sourceLocation = await mapErrorToSource(diagnosed.error, sourcePath);
         if (sourceLocation) {
           diagnosed.sourceLocation = sourceLocation;
         }
       }
     }
   }

   // UI auditing (vision analysis of error screenshots)
   const screenshotPaths = collectScreenshotsFromArtifact(executionResult);
   const uiAudits = await auditUI(executionResult);

   // Print analysis summary
   console.log('\nâœ“ Analysis Complete!');
   const aiPowered = !!process.env.GEMINI_API_KEY;
   console.log(`  Mode: ${aiPowered ? 'AI-powered (Gemini)' : 'Basic (set GEMINI_API_KEY for AI diagnosis)'}`);
   console.log(`  Errors diagnosed: ${diagnosedErrors.length}`);
   console.log(`  UI audits: ${uiAudits.length} screenshots analyzed`);
   if (sourcePath) {
     const withSource = diagnosedErrors.filter(d => d.sourceLocation).length;
     console.log(`  Source pinpointed: ${withSource}/${diagnosedErrors.length} errors`);
   }

   // Save analysis artifact
   const analysisArtifact: AnalysisArtifact = {
     version: '1.0.0',
     stage: 'analysis',
     timestamp: new Date().toISOString(),
     sessionId,
     diagnosedErrors,
     uiAudits,
     sourceAnalysisAvailable: !!sourcePath,
     aiPowered,
   };

   const artifactStorage = new ArtifactStorage();
   await artifactStorage.save(analysisArtifact);
   console.log(`\nAnalysis artifact saved: .afterburn/artifacts/analysis-${sessionId}.json`);
   ```

4. Move `process.exit(executionResult.exitCode)` to AFTER analysis is complete.

5. Print diagnosed errors summary (top 5):
   ```
   if (diagnosedErrors.length > 0) {
     console.log('\nTop Issues:');
     diagnosedErrors.slice(0, 5).forEach((d, i) => {
       console.log(`  ${i + 1}. ${d.summary}`);
       console.log(`     Fix: ${d.suggestedFix}`);
       if (d.sourceLocation) {
         console.log(`     Location: ${d.sourceLocation.file}:${d.sourceLocation.line}`);
       }
     });
   }
   ```

Note: The `diagnosed.error` field needs to come from somewhere -- the DiagnosedError should have the original error message. Check how error-analyzer.ts structures DiagnosedError and adjust field access accordingly. The key is to pass the original step error message to mapErrorToSource.

Keep existing discovery and execution output unchanged. Analysis is additive.
  </action>
  <verify>Run `npx tsc --noEmit` to confirm no type errors. Run `npm run build` to verify full compilation. Check that src/index.ts now has --source flag parsing and Phase 4 analysis stage after execution.</verify>
  <done>Complete pipeline works: Discovery -> Execution -> Analysis. Analysis phase diagnoses errors with AI, audits screenshots for UI issues, optionally pinpoints source code locations. Analysis artifact saved for Phase 5 reporting. --source flag accepted from CLI.</done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes with zero errors
2. `npm run build` compiles entire project successfully
3. src/index.ts accepts --source flag and passes it to analysis
4. Pipeline flow: discovery -> execution -> analysis -> exit
5. Analysis artifact saved to .afterburn/artifacts/analysis-{sessionId}.json
6. UI auditor calls generateStructuredWithImage with screenshots
7. Error diagnoses printed in plain English in terminal
8. Source locations shown when --source flag provided
</verification>

<success_criteria>
- Vision LLM audits screenshots for layout, contrast, and formatting issues
- Full pipeline integration: discovery -> execution -> analysis with artifact output
- --source CLI flag enables source code pinpointing
- Plain English error summaries and fix suggestions printed to terminal
- Analysis works with and without GEMINI_API_KEY (graceful degradation)
- All Phase 4 success criteria met:
  1. AI analyzes browser evidence for each error
  2. AI infers root cause with plain English explanation
  3. --source cross-references errors with source code
  4. Tool pinpoints file and line when source provided
  5. Vision LLM detects layout issues
  6. Vision LLM detects contrast and formatting issues
  7. AI provides UI improvement suggestions in plain English
</success_criteria>

<output>
After completion, create `.planning/phases/04-analysis-diagnosis/04-03-SUMMARY.md`
</output>
