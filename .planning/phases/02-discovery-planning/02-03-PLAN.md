---
phase: 02-discovery-planning
plan: 03
type: execute
wave: 2
depends_on: ["02-01", "02-02"]
files_modified:
  - src/discovery/link-validator.ts
  - src/discovery/sitemap-builder.ts
autonomous: true

must_haves:
  truths:
    - "Tool detects broken internal links (404, 500, network errors) during crawl"
    - "External links are recorded but not checked (to avoid rate limiting third-party sites)"
    - "Sitemap is structured as a hierarchical tree showing navigation paths (Home > Dashboard > Settings)"
    - "Every page in the sitemap includes its discovered interactive elements"
  artifacts:
    - path: "src/discovery/link-validator.ts"
      provides: "Broken link detection via HTTP status checking"
      exports: ["validateLinks"]
      min_lines: 40
    - path: "src/discovery/sitemap-builder.ts"
      provides: "Hierarchical sitemap tree builder from flat page data"
      exports: ["buildSitemap"]
      min_lines: 50
  key_links:
    - from: "src/discovery/link-validator.ts"
      to: "playwright Page.request"
      via: "page.request.get() for HTTP status checking"
      pattern: "page\\.request\\.get|request\\.get"
    - from: "src/discovery/sitemap-builder.ts"
      to: "src/types/discovery.ts"
      via: "Transforms PageData[] into SitemapNode tree"
      pattern: "SitemapNode|PageData"
---

<objective>
Build broken link detection and hierarchical sitemap construction from crawled page data.

Purpose: Broken link detection (TEST-06) runs during crawl to flag dead internal links. The sitemap builder transforms flat page data into a hierarchical tree that downstream phases (workflow planner, reports) consume. The sitemap is the primary artifact of Phase 2 — it's what gets saved and passed to Phase 3.

Output: `src/discovery/link-validator.ts` for broken link detection, `src/discovery/sitemap-builder.ts` for hierarchical tree construction.
</objective>

<execution_context>
@C:\Users\Shiv_\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\Shiv_\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/02-discovery-planning/02-CONTEXT.md
@.planning/phases/02-discovery-planning/02-RESEARCH.md
@src/types/artifacts.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Build broken link validator</name>
  <files>src/discovery/link-validator.ts</files>
  <action>
Create `src/discovery/link-validator.ts` with a `validateLinks` function.

**Import** `BrokenLink` and `LinkInfo` from `../types/discovery.js`.

**Function: validateLinks(links: LinkInfo[], page: Page): Promise&lt;BrokenLink[]&gt;**

Takes all links discovered on a page and checks internal ones for broken status.

Implementation:

1. Filter to internal links only (`link.isInternal === true`). External links are recorded but NOT checked (per context decision: avoid rate-limiting third-party sites).
2. Deduplicate links by href (don't check same URL twice).
3. Filter out non-HTTP links: skip `mailto:`, `tel:`, `javascript:`, `data:`, `#` fragment-only links.
4. For each internal link:
   - Use `page.request.get(url, { timeout: 5000 })` to check status
   - `page.request` maintains the browser session context (cookies, auth) which is important for sites that redirect unauthenticated requests
   - If response is not ok (status >= 400): add to brokenLinks with url, sourceUrl (page.url()), statusCode, statusText
   - If request throws (network error, timeout): add to brokenLinks with statusCode: 0 and error message as statusText
5. Process checks with concurrency limit (max 5 concurrent checks) to avoid overwhelming the server. Use a simple batch approach or Promise pool.
6. Return array of BrokenLink objects.

**Important edge cases:**
- Some servers reject HEAD requests — we use GET directly (simpler, more reliable)
- Redirects (301/302) should NOT be counted as broken — only final status matters. `page.request.get()` follows redirects by default.
- Ignore query-string-only differences from already-checked URLs
- Status 403 IS a broken link (forbidden = user can't access it)
- Status 401 may be expected for authenticated pages — still flag it, let the reporter decide significance

Export the function and add a 1-2 line header comment.
  </action>
  <verify>Run `npx tsc --noEmit` — no type errors.</verify>
  <done>validateLinks checks all internal links via HTTP GET, reports broken ones (4xx, 5xx, network errors), skips external links, and handles timeouts gracefully.</done>
</task>

<task type="auto">
  <name>Task 2: Build hierarchical sitemap tree builder</name>
  <files>src/discovery/sitemap-builder.ts</files>
  <action>
Create `src/discovery/sitemap-builder.ts` with a `buildSitemap` function.

**Import** `SitemapNode` and `PageData` from `../types/discovery.js`.

**Function: buildSitemap(pages: PageData[], rootUrl: string): SitemapNode**

Transforms a flat array of PageData into a hierarchical tree based on URL path structure.

Implementation:

1. Parse rootUrl to get the hostname and base path.
2. Create root node from the page matching rootUrl (or create a synthetic root if not found).
3. Sort pages by URL path depth (fewer `/` segments = closer to root).
4. For each page:
   - Parse URL to extract path segments (e.g., `/dashboard/settings` -> `['dashboard', 'settings']`)
   - Walk the tree from root following path segments
   - Create intermediate nodes if parent paths weren't crawled (e.g., if `/dashboard/settings` exists but `/dashboard` wasn't crawled, create a placeholder `/dashboard` node)
   - Attach page data to the matching node
5. Set depth on each node (root = 0, children = parent.depth + 1).

**SitemapNode construction per page:**
```typescript
{
  url: page.url,
  title: page.title,
  path: new URL(page.url).pathname,
  children: [],        // populated by tree building
  pageData: page,      // full PageData reference
  depth: 0,            // computed during tree building
}
```

**Edge cases:**
- Query-string pages (`/search?q=foo`): Treat as children of the path without query string (`/search`)
- Trailing slashes: Normalize before comparison (`/about/` = `/about`)
- Root path (`/`): Always the tree root
- Multiple pages at same path (different query params): Group under same parent
- Pages discovered via SPA routing may have paths that don't follow link hierarchy — still place by URL path

**Helper: printSitemapTree(node: SitemapNode, indent?: number): string**

Returns a human-readable tree string for CLI output:
```
Home (/)
  About (/about)
  Dashboard (/dashboard)
    Settings (/dashboard/settings)
    Profile (/dashboard/profile)
  Blog (/blog)
    Post: Hello World (/blog/hello-world)
```

Use indentation (2 spaces per level). Show title and path. This is for plain-English progress output (target audience: vibe coders).

Export both functions and add a 1-2 line header comment.
  </action>
  <verify>Run `npx tsc --noEmit` — no type errors.</verify>
  <done>buildSitemap constructs a hierarchical tree from flat page data using URL path structure. printSitemapTree renders it as human-readable indented text. Intermediate nodes are created for uncrawled parent paths.</done>
</task>

</tasks>

<verification>
- `npx tsc --noEmit` passes with zero errors
- `src/discovery/link-validator.ts` exports validateLinks
- `src/discovery/sitemap-builder.ts` exports buildSitemap and printSitemapTree
- Link validator only checks internal links (external links skipped)
- Sitemap is a proper tree with root node at depth 0
- Intermediate placeholder nodes created for uncrawled parent paths
</verification>

<success_criteria>
- Broken internal links (4xx, 5xx) are detected and reported
- External links are recorded but not HTTP-checked
- Sitemap tree correctly represents URL path hierarchy
- printSitemapTree produces readable, indented output
- Edge cases handled: trailing slashes, query params, SPA routes
</success_criteria>

<output>
After completion, create `.planning/phases/02-discovery-planning/02-03-SUMMARY.md`
</output>
